# train_and_infer.py
import os
import torch
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score
from transformers import (
    TrainingArguments,
    Trainer,
    AutoTokenizer,
    AutoModelForSequenceClassification
)
from peft import LoraConfig, get_peft_model
from utils import LLMDataset, ID2LABEL
import numpy as np
import torch
import torch.nn as nn  # âœ… ç¡®ä¿è¿™ä¸€è¡Œå­˜åœ¨
from transformers import AutoModelForCausalLM  # âœ… æ›¿æ¢ AutoModel
from tqdm import tqdm



# -----------------------------
# é…ç½®
# -----------------------------
MODEL_NAME = "Qwen/Qwen-1_8B-Chat"  #
OUTPUT_DIR = "models/fold_"
PREDICTION_DIR = "predictions/"
DATA_DIR = "data/"
NUM_FOLDS = 5
MAX_LENGTH = 512
BATCH_SIZE = 4
GRAD_ACCUM_STEPS = 4  # æ¨¡æ‹Ÿ batch_size = 4 * 4 = 16
LEARNING_RATE = 3e-4
EPOCHS = 3

os.makedirs(PREDICTION_DIR, exist_ok=True)

# å¼ºåˆ¶ä½¿ç”¨ PyTorch
os.environ['USE_TORCH'] = '1'
os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = '1'

# -----------------------------
# åŠ è½½ tokenizerï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
# -----------------------------
tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    trust_remote_code=True  # âš ï¸ å¿…é¡»æ·»åŠ 
)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token  # å¯¹ Qwen-7B æœ‰æ•ˆ
    # æˆ–è€…æ˜¾å¼è®¾ç½®ï¼š
    # tokenizer.pad_token = '<|endoftext|>'
tokenizer.padding_side = "left"  # Qwen æ¨è left-paddingï¼ˆå› ä¸ºæ˜¯ decoder-onlyï¼‰


# -----------------------------
# è‡ªå®šä¹‰ Qwen åˆ†ç±»æ¨¡å‹
# -----------------------------
class QwenForSequenceClassification(nn.Module):
    def __init__(self, model_name, num_labels=3, id2label=None, label2id=None):
        super().__init__()
        self.num_labels = num_labels
        self.id2label = id2label
        self.label2id = label2id

        # âœ… å…³é”®ï¼štrust_remote_code=True
        self.qwen = AutoModelForCausalLM.from_pretrained(
            model_name,
            trust_remote_code=True,
            dtype=torch.bfloat16,
            device_map="auto"
        )

        hidden_size = self.qwen.config.hidden_size
        self.classifier = nn.Linear(hidden_size, num_labels)
        nn.init.normal_(self.classifier.weight, std=0.02)
        nn.init.zeros_(self.classifier.bias)

    def forward(self, input_ids=None, attention_mask=None, labels=None):
        outputs = self.qwen(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = outputs.last_hidden_state
        batch_size = last_hidden_state.shape[0]
        sequence_lengths = attention_mask.sum(dim=1) - 1
        sequence_lengths = sequence_lengths.clamp(min=0)
        pooled_output = last_hidden_state[torch.arange(batch_size), sequence_lengths]
        logits = self.classifier(pooled_output)

        loss = None
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))
        return {"loss": loss, "logits": logits}

# -----------------------------
# 5æŠ˜äº¤å‰éªŒè¯ä¸»å¾ªç¯
# -----------------------------
fold_preds = []  # å­˜å‚¨æ¯æŠ˜å¯¹ test çš„é¢„æµ‹æ¦‚ç‡

for fold in range(NUM_FOLDS):
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ Fold {fold}")

    # 1. åŠ è½½æ•°æ®
    print("ğŸ“Š æ­£åœ¨åŠ è½½æ•°æ®...")
    train_df = pd.read_csv(f"{DATA_DIR}/fold{fold}_train.csv")
    val_df = pd.read_csv(f"{DATA_DIR}/fold{fold}_val.csv")
    test_df = pd.read_csv(f"{DATA_DIR}/test_clean.csv")

    # 2. æ„é€ è¾“å…¥æ–‡æœ¬
    print("ğŸ“ æ­£åœ¨æ„é€ è¾“å…¥æ–‡æœ¬...")
    def make_input(row):
        return f"Prompt: {row['prompt']}\nResponse A: {row['response_a']}\nResponse B: {row['response_b']}\nQuestion: Which response is better? Answer:"

    train_texts = train_df.apply(make_input, axis=1).tolist()
    val_texts = val_df.apply(make_input, axis=1).tolist()
    test_texts = test_df.apply(make_input, axis=1).tolist()

    train_labels = train_df['label'].tolist()
    val_labels = val_df['label'].tolist()

    # 3. åˆ›å»º dataset
    print("ğŸ’¾ æ­£åœ¨åˆ›å»ºæ•°æ®é›†...")
    train_dataset = LLMDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)
    val_dataset = LLMDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)

    # 4. åŠ è½½æ¨¡å‹ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
    print("ğŸ§  æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = QwenForSequenceClassification(
        MODEL_NAME,
        num_labels=3,
        id2label=ID2LABEL,
        label2id={v: k for k, v in ID2LABEL.items()}  # å‡è®¾ LABEL2ID æœªå®šä¹‰
    )

    # 5. æ·»åŠ  LoRA
    print("ğŸ”§ æ­£åœ¨é…ç½®LoRA...")
    lora_config = LoraConfig(
        r=8,
        lora_alpha=16,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],  # Qwen çš„æ¨¡å—å
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",  # æ³¨æ„ï¼šè™½ç„¶åšåˆ†ç±»ï¼Œä½† Qwen æ˜¯ causal LM
        modules_to_save=["classifier"]  # âœ… å…³é”®ï¼å¿…é¡»ä¿å­˜åˆ†ç±»å¤´
    )

    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()  # åº”æ˜¾ç¤ºå°‘é‡å¯è®­ç»ƒå‚æ•°

    # 6. è®­ç»ƒå‚æ•°
    print("âš™ï¸ æ­£åœ¨è®¾ç½®è®­ç»ƒå‚æ•°...")
    training_args = TrainingArguments(
        output_dir=f"{OUTPUT_DIR}{fold}",
        num_train_epochs=EPOCHS,
        per_device_train_batch_size=BATCH_SIZE,
        gradient_accumulation_steps=GRAD_ACCUM_STEPS,
        per_device_eval_batch_size=BATCH_SIZE,
        learning_rate=LEARNING_RATE,
        weight_decay=0.01,
        logging_steps=10,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="eval_macro_f1",
        greater_is_better=True,
        save_total_limit=1,
        report_to="none",  # ä¸ä¸Šä¼ wandbç­‰
        fp16=True,  # ä½¿ç”¨æ··åˆç²¾åº¦
        remove_unused_columns=False,
        warmup_ratio=0.1,
        seed=42,
    )

    # 7. å®šä¹‰è¯„ä¼°æŒ‡æ ‡
    print("ğŸ“ˆ æ­£åœ¨å®šä¹‰è¯„ä¼°æŒ‡æ ‡...")
    def compute_metrics(eval_pred):
        predictions, labels = eval_pred
        preds = predictions.argmax(-1)
        macro_f1 = f1_score(labels, preds, average='macro')
        acc = accuracy_score(labels, preds)
        return {"accuracy": acc, "macro_f1": macro_f1}

    # 8. åˆ›å»º Trainer
    print("ğŸ¯ æ­£åœ¨åˆ›å»ºTrainer...")
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics
    )

    # 9. å¼€å§‹è®­ç»ƒ
    print("ğŸ”¥ æ­£åœ¨å¼€å§‹è®­ç»ƒ...")
    with tqdm(total=training_args.num_train_epochs, desc="Epochs") as pbar:
        for epoch in range(training_args.num_train_epochs):
            # æ‰§è¡Œè®­ç»ƒ
            trainer.train()
            pbar.update(1)

    # 10. éªŒè¯é›†é¢„æµ‹ï¼ˆå¯é€‰ï¼šçœ‹æ¯æŠ˜æ€§èƒ½ï¼‰
    print("ğŸ” æ­£åœ¨è¿›è¡ŒéªŒè¯é›†é¢„æµ‹...")
    val_preds = trainer.predict(val_dataset)
    val_pred_labels = val_preds.predictions.argmax(-1)
    val_true_labels = val_preds.label_ids
    macro_f1 = f1_score(val_true_labels, val_pred_labels, average='macro')
    print(f"Fold {fold} éªŒè¯é›† Macro F1: {macro_f1:.4f}")

    # 11. å¯¹ test é›†é¢„æµ‹ï¼ˆè¾“å‡ºæ¦‚ç‡ï¼‰
    print("ğŸ§ª æ­£åœ¨è¿›è¡Œæµ‹è¯•é›†é¢„æµ‹...")
    test_dataset = LLMDataset(test_texts, ["A"] * len(test_texts), tokenizer, MAX_LENGTH)  # labelå ä½
    test_preds = trainer.predict(test_dataset)
    test_probs = torch.nn.functional.softmax(torch.tensor(test_preds.predictions), dim=-1).numpy()  # (N, 3)
    fold_preds.append(test_probs)

    # 12. é‡Šæ”¾æ˜¾å­˜
    print("ğŸ§¹ æ­£åœ¨æ¸…ç†æ˜¾å­˜...")
    del model, trainer
    torch.cuda.empty_cache()


# -----------------------------
# ç¬¬å››æ­¥ï¼šé›†æˆé¢„æµ‹ï¼ˆ5æŠ˜å¹³å‡ï¼‰
# -----------------------------
# æ‰€æœ‰ fold çš„é¢„æµ‹æ¦‚ç‡å¹³å‡
final_probs = np.mean(fold_preds, axis=0)  # (N, 3)
final_preds = final_probs.argmax(axis=1)  # å–æœ€å¤§æ¦‚ç‡
final_labels = [ID2LABEL[i] for i in final_preds]

# -----------------------------
# ç¬¬äº”æ­¥ï¼šç”Ÿæˆæäº¤æ–‡ä»¶
# -----------------------------
submission = pd.DataFrame({
    'id': test_df['id'],
    'label': final_labels
})
submission.to_csv(f"{PREDICTION_DIR}/submission_ensemble.csv", index=False)
print("âœ… æäº¤æ–‡ä»¶ç”Ÿæˆå®Œæ¯•ï¼")
print(submission['label'].value_counts())